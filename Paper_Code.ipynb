{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich verschiedener CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipywidgets import interact,interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import cv2\n",
    "directory = './GTSRB/Final_Training/Images'\n",
    "directory_Test = './GTSRB/Final_Test/Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvertiere Bilder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konvertiere die PPM Bilder in JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# rootdir = directory\n",
    "# extensions = ('.ppm')\n",
    "\n",
    "# for subdir, dirs, files in os.walk(rootdir):\n",
    "#     for file in files:\n",
    "#         ext = os.path.splitext(file)[-1].lower()\n",
    "#         if ext in extensions:\n",
    "#             new_extension = \".jpg\"\n",
    "#             path_str = os.path.join(subdir, file)\n",
    "#             pre, ext = os.path.splitext(path_str)\n",
    "#             path_renamed = pre + new_extension\n",
    "#             i = cv2.imread(path_str)\n",
    "#             cv2.imwrite(path_renamed,i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globale Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 43\n",
    "num_epochs = 40\n",
    "num_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenaufbereitung\n",
    "Laden der Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 files belonging to 43 classes.\n",
      "Using 31368 files for training.\n",
      "Found 39209 files belonging to 43 classes.\n",
      "Using 7841 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=0,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=num_batch_size,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "ds_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=num_batch_size,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=1,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisiere Bilder: 0-255 -> 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "norm_train = ds_train.map(lambda x, y: (normalization_layer(x), y))\n",
    "norm_test = ds_test.map(lambda x, y: (normalization_layer(x), y))\n",
    "ds_train = norm_train\n",
    "ds_test = norm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau der verschiedenen Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelle ohne Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res50v2 = tf.keras.applications.ResNet50V2(weights=None, input_shape=(128, 128, 3), classes=num_classes)\n",
    "# xception = tf.keras.applications.Xception(weights=None, input_shape=(128, 128, 3), classes=num_classes)\n",
    "# vgg16 = tf.keras.applications.VGG16(weights=None, input_shape=(128, 128, 3), classes=num_classes)\n",
    "# vgg19 = tf.keras.applications.VGG19(weights=None, input_shape=(128, 128, 3), classes=num_classes)\n",
    "# mobv2 = tf.keras.applications.MobileNetV2(weights=None, input_shape=(128, 128, 3), classes=num_classes)\n",
    "# inceptv3 = tf.keras.applications.InceptionV3(weights=None, input_shape=(128, 128, 3), classes=num_classes)\n",
    "# resnet152v2 = tf.keras.applications.ResNet152V2(weights=None, input_shape=(128, 128, 3), classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelle mit Imagenet Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50v2PT = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape=(128, 128, 3),include_top = False, classes=num_classes)\n",
    "xceptionPT = tf.keras.applications.Xception(weights='imagenet', input_shape=(128, 128, 3),include_top = False, classes=num_classes)\n",
    "vgg16PT = tf.keras.applications.VGG16(weights='imagenet', input_shape=(128, 128, 3), include_top = False,classes=num_classes)\n",
    "vgg19PT = tf.keras.applications.VGG19(weights='imagenet', input_shape=(128, 128, 3),include_top = False, classes=num_classes)\n",
    "mobv2PT = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(128, 128, 3), include_top = False,classes=num_classes)\n",
    "inceptv3PT = tf.keras.applications.InceptionV3(weights='imagenet', input_shape=(128, 128, 3), include_top = False,classes=num_classes)\n",
    "resnet152v2PT = tf.keras.applications.ResNet152V2(weights='imagenet', input_shape=(128, 128, 3),include_top = False, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinzuf√ºgen der Klassifizierungs Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "res50v2PT.trainable = True\n",
    "res50v2PT = tf.keras.Sequential([\n",
    "  res50v2PT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "res50v2PT.add(Activation('softmax'))\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "xceptionPT.trainable = True\n",
    "xceptionPT = tf.keras.Sequential([\n",
    "  xceptionPT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "xceptionPT.add(Activation('softmax'))\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "vgg16PT.trainable = True\n",
    "vgg16PT = tf.keras.Sequential([\n",
    "  vgg16PT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "vgg16PT.add(Activation('softmax'))\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "vgg19PT.trainable = True\n",
    "vgg19PT = tf.keras.Sequential([\n",
    "  vgg19PT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "vgg19PT.add(Activation('softmax'))\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "mobv2PT.trainable = True\n",
    "mobv2PT = tf.keras.Sequential([\n",
    "  mobv2PT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "mobv2PT.add(Activation('softmax'))\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "inceptv3PT.trainable = True\n",
    "inceptv3PT = tf.keras.Sequential([\n",
    "  inceptv3PT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "inceptv3PT.add(Activation('softmax'))\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "resnet152v2PT.trainable = True\n",
    "resnet152v2PT = tf.keras.Sequential([\n",
    "  resnet152v2PT,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "resnet152v2PT.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kompilieren des Modells\n",
    "Eine detaillierte Beschreibung der [compile](https://keras.io/api/models/model_training_apis/#compile-method)-Methode findest du in Keras API Referenz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res50v2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# xception.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# vgg16.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# vgg19.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# mobv2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# inceptv3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# resnet152v2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50v2PT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "xceptionPT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "vgg16PT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "vgg19PT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "mobv2PT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "inceptv3PT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "resnet152v2PT.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt,\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = []\n",
    "# for batch in ds_train:\n",
    "#     for lab in batch[1]:\n",
    "#         y_train.append(lab.numpy())\n",
    "# y_train = np.argmax(y_train, axis=1)\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_train),\n",
    "#                                                  y_train)\n",
    "# class_weights=dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2b50f23324797dc9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2b50f23324797dc9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training der Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard = TensorBoard(log_dir=\"logs/resnet152v2\")\n",
    "# histRes = resnet152v2.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# resnet152v2.save('resnet152v2.h5')\n",
    "# del resnet152v2\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/res50\")\n",
    "# histRes = res50v2.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# res50v2.save('res50v2.h5')\n",
    "# del res50v2\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/xception\")\n",
    "# histXC = xception.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# xception.save('xception.h5')\n",
    "# del xception\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/vgg16\")\n",
    "# histvgg16 = vgg16.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# vgg16.save('vgg16.h5')\n",
    "# del vgg16\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/vgg19\")\n",
    "# histVgg19 = vgg19.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# vgg19.save('vgg19.h5')\n",
    "# del vgg19\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/mobv2\")\n",
    "# histMobv2 = mobv2.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# mobv2.save('mobv2.h5')\n",
    "# del mobv2\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/inceptv3\")\n",
    "# histInc = inceptv3.fit(ds_train, epochs=num_epochs, validation_data=ds_test, callbacks=[tensorboard])\n",
    "# inceptv3.save('inceptv3.h5')\n",
    "# del inceptv3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(predictions==ground_truth))\n",
    "# print(classification_report(ground_truth,predictions))\n",
    "# print(confusion_matrix(ground_truth,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden des Test Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12630 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Lade das trainierte Modell und teste die Erkennung der Verkehrszeichen-Klassen mit eigenen Beispielen\n",
    "ds_true_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory_Test,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=0,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=256,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=None,\n",
    "    seed=1,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "norm_true_test = ds_true_test.map(lambda x, y: (normalization_layer(x), y))\n",
    "ds_true_test = norm_true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true_test = []\n",
    "for batch in ds_true_test:\n",
    "    for img in batch[0]:\n",
    "        x_true_test.append(img.numpy())\n",
    "x_true_test = np.array(x_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "ground_truth = []\n",
    "with open('ground_truth.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        for row in csv_reader:\n",
    "            ground_truth.append(int(row[-1]))\n",
    "ground_truth = np.array(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung der Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED Weights not locked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 pretrained Accuracy: 0.969200316706255\n",
      "Millisekunden Pro Bild: 0.924\n",
      "MobileNetV2 pretrained Accuracy: 0.9827395091053048\n",
      "Millisekunden Pro Bild: 0.447\n",
      "ResNet50v2 pretrained Accuracy: 0.9803642121931908\n",
      "Millisekunden Pro Bild: 0.785\n",
      "ResNet152v2 pretrained Accuracy: 0.9704671417260491\n",
      "Millisekunden Pro Bild: 1.814\n",
      "VGG16 pretrained Accuracy: 0.9724465558194775\n",
      "Millisekunden Pro Bild: 0.824\n",
      "VGG19 pretrained Accuracy: 0.9519398258115598\n",
      "Millisekunden Pro Bild: 0.848\n",
      "Xception pretrained Accuracy: 0.9882818685669041\n",
      "Millisekunden Pro Bild: 0.943\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model = keras.models.load_model('inceptv3PTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"InceptionV3 pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('mobv2PTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"MobileNetV2 pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('res50v2PTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"ResNet50v2 pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('resnet152v2PTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"ResNet152v2 pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('vgg16PTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"VGG16 pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('vgg19PTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"VGG19 pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('xceptionPTTrainable.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"Xception pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRETRAINED Feature-Weights locked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 pretrained, weights locked Accuracy: 0.6942992874109264\n",
      "Millisekunden Pro Bild: 0.783\n",
      "MobileNetV2 pretrained, weights locked Accuracy: 0.7580364212193191\n",
      "Millisekunden Pro Bild: 0.378\n",
      "ResNet50v2 pretrained, weights locked Accuracy: 0.7729216152019003\n",
      "Millisekunden Pro Bild: 0.748\n",
      "ResNet152v2 pretrained, weights locked Accuracy: 0.755581947743468\n",
      "Millisekunden Pro Bild: 1.629\n",
      "VGG16 pretrained, weights locked Accuracy: 0.6688836104513064\n",
      "Millisekunden Pro Bild: 0.822\n",
      "VGG19 pretrained, weights locked Accuracy: 0.6038796516231195\n",
      "Millisekunden Pro Bild: 0.849\n",
      "Xception pretrained, weights locked Accuracy: 0.7068091844813935\n",
      "Millisekunden Pro Bild: 0.909\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model = keras.models.load_model('inceptv3PT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"InceptionV3 pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('mobv2PT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"MobileNetV2 pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('res50v2PT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"ResNet50v2 pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('resnet152v2PT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"ResNet152v2 pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('vgg16PT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"VGG16 pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('vgg19PT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"VGG19 pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('xceptionPT.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"Xception pretrained, weights locked Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 not pretrained Accuracy: 0.057007125890736345\n",
      "Millisekunden Pro Bild: 0.947\n",
      "VGG19 not pretrained Accuracy: 0.057007125890736345\n",
      "Millisekunden Pro Bild: 0.896\n",
      "Xception not pretrained Accuracy: 0.979889152810768\n",
      "Millisekunden Pro Bild: 0.904\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model('inceptv3.h5')\n",
    "# predictions_test = model.predict(x_true_test)\n",
    "# predictions_test = np.argmax(predictions_test, axis=1)\n",
    "# print(\"InceptionV3 not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "# print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('mobv2.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"MobileNetV2 not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('res50v2.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"ResNet50v2 not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "# start = time()\n",
    "# model = keras.models.load_model('resnet152v2.h5')\n",
    "# predictions_test = model.predict(x_true_test)\n",
    "# predictions_test = np.argmax(predictions_test, axis=1)\n",
    "# print(\"ResNet152v2 not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "# print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('vgg16.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"VGG16 not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('vgg19.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"VGG19 not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n",
    "\n",
    "start = time()\n",
    "model = keras.models.load_model('xception.h5')\n",
    "predictions_test = model.predict(x_true_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "print(\"Xception not pretrained Accuracy: \" + str(np.mean(predictions_test==ground_truth)))\n",
    "print(\"Millisekunden Pro Bild: \" + str(np.round((time()-start)/len(ground_truth)*1000,3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting Model Predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('employee_file.csv') as csv_file:\n",
    "    with open('output.csv', mode='w') as employee_file:\n",
    "        employee_writer = csv.writer(employee_file, delimiter=';')\n",
    "        csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "        for i,row in enumerate(csv_reader):\n",
    "            employee_writer.writerow([row[0],predictions_test[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
